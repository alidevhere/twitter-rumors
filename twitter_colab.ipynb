{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/programmingLover12/twitter/blob/main/twitter_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW714p7mSjgW"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2urrY3qhTKeu",
        "outputId": "5ae883a0-fd12-4da8-8e25-98e5f6080c96"
      },
      "source": [
        "cd /content/drive/MyDrive/CSV_Files/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CSV_Files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQwQ_HpITLgy"
      },
      "source": [
        "# 0 = non- rumor , 1 = rumor\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,SimpleRNN,LSTM,GRU,Bidirectional\n",
        "# adding temporal cnn\n",
        "#from tcn import TCN, tcn_full_summary\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import load_model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue8wlD6eTNwK"
      },
      "source": [
        "def load_data(event,time=60):\n",
        "    events = [\"charliehebdo\", \"ferguson\", \"germanwings-crash\", \"gurlitt\", \"ottawashooting\", \"putinmissing\",\n",
        "                \"sydneysiege\"]\n",
        "    data = pd.read_csv(f'CSV_Files/{events[event]}.csv', names=['timeDiff', 'status', 'Freq'], header=0)\n",
        "    \n",
        "    \n",
        "    data = data[data['timeDiff'] <= time]\n",
        "    print(data)\n",
        "    return data\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Plwec_pTQRi"
      },
      "source": [
        "def split_train_test(training):\n",
        "    '''\n",
        "    x_train = training[['timeDiff','Freq']]\n",
        "    scaler =  MinMaxScaler(feature_range=(0,1))\n",
        "    x_train = scaler.fit_transform(training[['status']].values.reshape(-1, 1))\n",
        "    print(x_train)\n",
        "    print('===============')\n",
        "    train_size = int(len(x_train) * 0.7)\n",
        "    test_size = len(x_train) - train_size\n",
        "    train, test = x_train[0:train_size,:], x_train[train_size:len(x_train),:]\n",
        "\n",
        "    return train,test\n",
        "    '''\n",
        "\n",
        "    x_train = training[['timeDiff','Freq']]\n",
        "    scaler =  MinMaxScaler(feature_range=(0,1))\n",
        "    x_train = scaler.fit_transform(x_train)\n",
        "    x_train = np.append(x_train,training[['status']],axis=1)\n",
        "\n",
        "    print('X_train')\n",
        "    print(x_train)\n",
        "    \n",
        "    print(x_train.shape)\n",
        "    train_size = int(len(x_train) * 0.7)\n",
        "    test_size = len(x_train) - train_size\n",
        "    train, test = x_train[0:train_size,:], x_train[train_size:len(x_train),:]\n",
        "\n",
        "    return train,test\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I72Tg5R6TV08",
        "outputId": "f080095c-aabb-4466-db63-529ae0e79ccf"
      },
      "source": [
        "\n",
        "def create_dataset(x_train, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(x_train)-look_back-1):\n",
        "        a = x_train[i:(i+look_back), 0:2]\n",
        "        dataX.append(a)\n",
        "        dataY.append(x_train[i + look_back, 0:1])\n",
        "    return np.array(dataX), np.array(dataY)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ottawashooting.csv', 'prince-toronto.csv', 'sydneysiege.csv', 'gurlitt.csv', 'DataDescription.csv', 'charliehebdo.csv', 'germanwings-crash.csv', 'ferguson.csv', 'putinmissing.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMBAtZiUT9bp"
      },
      "source": [
        "def build_tcnn(x_train,y_train,save, event_name,time):\n",
        "    look_back=1\n",
        "    model = Sequential() \n",
        "    model.add(TCN(input_shape=(x_train.shape[1], look_back)) )\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse',metrics=[\"accuracy\"])\n",
        "\n",
        "    tcn_full_summary(model, expand_residual_blocks=False)\n",
        "    model.fit(x_train, y_train, epochs=5)#, validation_split=0.2\n",
        "\n",
        "    if save == True: \n",
        "        model.save(f'{models_dir}/TCNN/TCNN_{event_name}_{time}')\n",
        "    return model\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uvYNKrlUfWI"
      },
      "source": [
        "\n",
        "def build_LSTM(x_train,y_train,save,event_name,time):\n",
        "    #,x_test, y_test\n",
        "    look_back = 1\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(256, return_sequences = True, input_shape = (x_train.shape[1], look_back)))\n",
        "    model.add(LSTM(128,input_shape = (x_train.shape[1], look_back)))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    model.compile( loss='mean_squared_error', optimizer='adam',metrics=[\"accuracy\"])\n",
        "    model.summary()\n",
        "    model.fit(x_train, y_train, epochs=100, batch_size=64, verbose=2)\n",
        "    \n",
        "    if save == True: \n",
        "        model.save(f'{models_dir}/LSTM/LSTM_{event_name}_{time}')\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odxNhp8-VSW9"
      },
      "source": [
        "def build_RNN(x_train,y_train,save,event_name,time):\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(layers.Embedding(input_dim=100, output_dim=64))\n",
        "    # The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "    model.add(SimpleRNN(128))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    #sigmoid added- 1 unit\n",
        "    model.summary()\n",
        "\n",
        "    model.compile( loss='mean_squared_error', optimizer='adam',metrics=[\"accuracy\"])\n",
        "    \n",
        "    model.fit(x_train, y_train, epochs=5, batch_size=64, verbose=2)\n",
        "\n",
        "    if save==True:        \n",
        "        model.save(f'{models_dir}/SimpleRNN/SimpleRNN_{event_name}_{time}')\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vt_TsFbVUXe",
        "outputId": "f4109eaf-9360-4dca-d91f-1c3c7ea15459"
      },
      "source": [
        "def build_GRU(x_train, y_train,save,event_name,time):\n",
        "\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Embedding(input_dim=100, output_dim=64))\n",
        "    # The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
        "    model.add(GRU(256, return_sequences=True))\n",
        "\n",
        "    # The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "    model.add(SimpleRNN(128))\n",
        "\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "    \n",
        "    model.compile( loss='mean_squared_error', optimizer='adam',metrics=[\"accuracy\"])\n",
        "    model.fit(x_train, y_train, epochs=5, batch_size=64, verbose=2)\n",
        "    \n",
        "    if save==True:\n",
        "        model.save(f'{models_dir}/GRU/GRU_{event_name}_{time}')\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19409, 1)\n",
            "(19409,)\n",
            "(8317, 1)\n",
            "(8317,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY1lBjDjVWVs"
      },
      "source": [
        "def build_bi_LSTM(x_train, y_train,save,event_name,time):\n",
        "    model = keras.Sequential()\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(5, 1)) )\n",
        "    model.add(Bidirectional(LSTM(32)))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    model.summary()\n",
        "\n",
        "    model.compile( loss='mean_squared_error', optimizer='adam',metrics=[\"accuracy\"])\n",
        "    model.fit(x_train, y_train, epochs=5, batch_size=64, verbose=2)\n",
        "    # epochs=20 changing to 30\n",
        "\n",
        "    if save==True:\n",
        "        model.save(f'{models_dir}/BiLSTM/BiLSTM_{event_name}_{time}')\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXAuA8owVYP9",
        "outputId": "4419cd41-6a29-4369-b3e7-c15fa58aae54"
      },
      "source": [
        "def load_models(event,time):\n",
        "    # loading mdoel\n",
        "    models = []\n",
        "    models.append(keras.models.load_model(f'{models_dir}/LSTM/LSTM_{event_name}_{time}'))\n",
        "    models.append(keras.models.load_model(f'{models_dir}/SimpleRNN/SimpleRNN_{event_name}_{time}') )\n",
        "    models.append(keras.models.load_model(f'{models_dir}/GRU/GRU_{event_name}_{time}'))\n",
        "    models.append(keras.models.load_model(f'{models_dir}/BiLSTM/BiLSTM_{event_name}_{time}'))\n",
        "    models.append(keras.models.load_model(f'{models_dir}/TCNN/TCNN_{event_name}_{time}'))\n",
        "    return models\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19409, 1, 1)\n",
            "(19409, 1)\n",
            "(8317, 1, 1)\n",
            "(8317, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei1tyyo0Va-N"
      },
      "source": [
        "def Ensembler_result(models,x_test):\n",
        "    array = None\n",
        "    for model in models:\n",
        "        if array is None:\n",
        "            array = model.predict(x_test)\n",
        "        else:\n",
        "            a = model.predict(x_test)\n",
        "            array = np.append(array,a, axis=1)\n",
        "    \n",
        "    result = []\n",
        "    for row in iter(array):\n",
        "        if (row >= 0.50).sum() >=3:\n",
        "            result.append(1)\n",
        "        else:\n",
        "            result.append(0)\n",
        "        \n",
        "    return np.array(result)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K3dqodXWTc9"
      },
      "source": [
        "def main(EVENT,TIME,RUN_FROM_SAVED_MODELS,SAVE_MODEL_AFTER_TRAINING):\n",
        "    \n",
        "    #[\"charliehebdo\", \"ferguson\", \"germanwings-crash\", \"gurlitt\", \"ottawashooting\", \"putinmissing\",\"sydneysiege\"]\n",
        "    # time in seocnds\n",
        "    data = load_data(event = EVENT, time=TIME)\n",
        "    \n",
        "    train, test = split_train_test(data)\n",
        "    \n",
        "    x_train, y_train = create_dataset(train, look_back=1)\n",
        "    x_test, y_test = create_dataset(test, look_back=1)\n",
        "    \n",
        "    # reshaping\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
        "    \n",
        "    # Running and Saving Models\n",
        "    model1 = build_LSTM(x_train,y_train,SAVE_MODEL_AFTER_TRAINING    ,EVENT,TIME )\n",
        "    model2 = build_GRU(x_train,y_train,SAVE_MODEL_AFTER_TRAINING     ,EVENT,TIME  )\n",
        "    model3 = build_bi_LSTM(x_train,y_train,SAVE_MODEL_AFTER_TRAINING ,EVENT,TIME  )\n",
        "    model4 = build_RNN(x_train,y_train,SAVE_MODEL_AFTER_TRAINING     ,EVENT,TIME  )    \n",
        "    model5 = build_tcnn(x_train,y_train,SAVE_MODEL_AFTER_TRAINING    ,EVENT,TIME  )\n",
        "\n",
        "    \n",
        "    if RUN_FROM_SAVED_MODELS == True:\n",
        "        models = load_models(EVENT,TIME)\n",
        "    \n",
        "    else: # use above build models \n",
        "        models = []\n",
        "        models.append(model1)\n",
        "        models.append(model2)\n",
        "        models.append(model3)\n",
        "        models.append(model4)\n",
        "        models.append(model5)\n",
        "\n",
        "\n",
        "    result =  Ensembler_result(models,x_test)\n",
        "\n",
        "    r = (result == y_test).sum()\n",
        "    acc = r/len(y_test)\n",
        "    \n",
        "    TP,TN,FP,FN = build_confusion_matrix(y_test,result)\n",
        "    \n",
        "    accuracy = (TN+TP) /(TN+TP+FN+FP)\n",
        "    precision = TP / (TP+FP)\n",
        "    recall = TP /(TP+FN)\n",
        "\n",
        "    f1_score = 2*((precision * recall)/(precision + recall))\n",
        "\n",
        "    print('accuracy = ',accuracy)\n",
        "    print('precision = ',precision)\n",
        "    print('recall = ',recall)\n",
        "    print('f1 score = ',f1_score)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "WYNgQ8nVLKRO",
        "outputId": "35927024-0203-4174-dba8-da4eb0d0f17e"
      },
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    # JUST CHANGE PARAMETERS HERE\n",
        "    # charliehebdo=0, ferguson=1, germanwings-crash=2, gurlitt=3, ottawashooting=4, putinmissing=5,sydneysiege=6\n",
        "\n",
        "    #=====================\n",
        "    EVENT = 0\n",
        "    # in seconds  120,300,600,1800,3600\n",
        "    TIME = 3600\n",
        "    #t=[120,300,600,1800,3600]\n",
        "\n",
        "    RUN_FROM_SAVED_MODELS = False\n",
        "    \n",
        "    SAVE_MODEL_AFTER_TRAINING=False\n",
        "    \n",
        "    #main(0,3600,RUN_FROM_SAVED_MODELS,SAVE_MODEL_AFTER_TRAINING)\n",
        "    \n",
        "    \n",
        "    data = load_data(event = EVENT, time=TIME)\n",
        "    \n",
        "    train, test = split_train_test(data)\n",
        "    \n",
        "    #print('train=====')\n",
        "    #print(train)\n",
        "    #print('test=====')\n",
        "    #print(test)\n",
        "\n",
        "    #x_train, y_train = create_dataset(train, look_back=1)\n",
        "\n",
        "    x_train = train[:,0:2]\n",
        "    y_train = np.transpose(train[:, 2])\n",
        "    print('xtrain=====')\n",
        "    print(x_train)\n",
        "    print(x_train.shape)\n",
        "    print('ytrain=====')\n",
        "    print(y_train)\n",
        "    print(y_train.shape)\n",
        "    \n",
        "\n",
        "    #x_test, y_test = create_dataset(test, look_back=1)\n",
        "    #\n",
        "    ## reshaping\n",
        "    #x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
        "    #x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
        "    #\n",
        "    ## Running and Saving Models\n",
        "    model1 = build_LSTM(x_train,y_train,SAVE_MODEL_AFTER_TRAINING    ,EVENT,TIME )\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4bc0536cc600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEVENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTIME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-47bd735d51cc>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(event, time)\u001b[0m\n\u001b[1;32m      2\u001b[0m     events = [\"charliehebdo\", \"ferguson\", \"germanwings-crash\", \"gurlitt\", \"ottawashooting\", \"putinmissing\",\n\u001b[1;32m      3\u001b[0m                 \"sydneysiege\"]\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'CSV_Files/{events[event]}.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timeDiff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'status'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timeDiff'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CSV_Files/charliehebdo.csv'"
          ]
        }
      ]
    }
  ]
}