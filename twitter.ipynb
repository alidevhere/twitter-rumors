{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/programmingLover12/twitter/blob/main/twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW714p7mSjgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d4ff40-b32a-4b0d-f067-abd4251b8d5f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2urrY3qhTKeu",
        "outputId": "b0adaaee-aa81-4e89-e700-38d019a2e7fc"
      },
      "source": [
        "cd /content/drive/MyDrive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQwQ_HpITLgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61ceb0c-fe22-4efc-d0cc-fb9f6242d2fa"
      },
      "source": [
        "# 0 = non- rumor , 1 = rumor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,SimpleRNN,LSTM,GRU,Bidirectional\n",
        "# adding temporal cnn\n",
        "#from tcn import TCN, tcn_full_summary\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import load_model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from  sklearn.model_selection import train_test_split\n",
        "# adding temporal cnn\n",
        "!pip install keras-tcn --no-dependencies\n",
        "from tcn import TCN, tcn_full_summary\n",
        "models_dir= \"/content/drive/MyDrive/CSV_Files/Models\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tcn\n",
            "  Downloading https://files.pythonhosted.org/packages/84/31/579d2dccda0a7d5ef5839b3f73257a5209dffafd319f6d1cebb16007d3fc/keras_tcn-3.4.0-py2.py3-none-any.whl\n",
            "Installing collected packages: keras-tcn\n",
            "Successfully installed keras-tcn-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue8wlD6eTNwK"
      },
      "source": [
        "def load_data(event,time=60):\n",
        "    events = [\"charliehebdo\", \"ferguson\", \"germanwings-crash\", \"gurlitt\", \"ottawashooting\", \"putinmissing\",\n",
        "                \"sydneysiege\"]\n",
        "    data = pd.read_csv(f'CSV_Files/{events[event]}.csv', names=['timeDiff', 'status', 'Freq'], header=0)\n",
        "    \n",
        "    data = data[data['timeDiff'] <= time]\n",
        "    print(data)\n",
        "    return data\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Plwec_pTQRi"
      },
      "source": [
        "def split_train_test(training):\n",
        "    scaler =  MinMaxScaler(feature_range=(0,1))\n",
        "    training = scaler.fit_transform(training)\n",
        "    train, test = train_test_split(training, test_size=0.3)\n",
        "    return train, test\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMBAtZiUT9bp"
      },
      "source": [
        "def build_tcnn(x_train,y_train,save, event_name,time,epoch=50):\n",
        "    #!cd /content/drive/MyDrive/CSV_Files/Models\n",
        "    seq = len(x_train)\n",
        "    units = int((seq +2) / 2)\n",
        "    look_back = 2\n",
        "\n",
        "    model = Sequential() \n",
        "    model.add(TCN(units ,input_shape=(x_train.shape[1], look_back)) )\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse',metrics=[\"accuracy\"])\n",
        "\n",
        "    tcn_full_summary(model, expand_residual_blocks=False)\n",
        "    model.fit(x_train, y_train, epochs=epoch)#, validation_split=0.2\n",
        "\n",
        "    if save == True: \n",
        "        model.save(f'{models_dir}/TCNN/TCNN_{event_name}_{time}')\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uvYNKrlUfWI"
      },
      "source": [
        "\n",
        "def build_LSTM(x_train,y_train,save,event_name,time,epoch=300):\n",
        "    #,x_test, y_test\n",
        "    seq = len(x_train)\n",
        "    units = int((seq +2) / 2)\n",
        "    look_back = 2\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units, input_shape = (x_train.shape[1], look_back)))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    model.compile( loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
        "    model.summary()\n",
        "    model.fit(x_train, y_train, epochs=epoch, batch_size=32, verbose=2)\n",
        "    \n",
        "    if save == True: \n",
        "        model.save(f'{models_dir}/LSTM/LSTM_{event_name}_{time}')\n",
        "    return model\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odxNhp8-VSW9"
      },
      "source": [
        "def build_RNN(x_train,y_train,save,event_name,time,epoch=300):\n",
        "    seq = len(x_train)\n",
        "    units = int((seq +2) / 2)\n",
        "    look_back =2\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(units, input_shape = (x_train.shape[1], look_back)))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    model.compile( loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
        "    model.summary()\n",
        "    model.fit(x_train, y_train, epochs=epoch, batch_size=32, verbose=2)\n",
        "\n",
        "    if save==True:        \n",
        "        model.save(f'{models_dir}/SimpleRNN/SimpleRNN_{event_name}_{time}')\n",
        "    return model\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vt_TsFbVUXe"
      },
      "source": [
        "def build_GRU(x_train, y_train,save,event_name,time,epoch=300):\n",
        "    seq = len(x_train)\n",
        "    units = int((seq +2) / 2)\n",
        "    look_back =2\n",
        "    model = keras.Sequential()\n",
        "    model.add(GRU(units, input_shape = (x_train.shape[1], look_back)))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    model.compile( loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
        "    model.summary()\n",
        "    model.fit(x_train, y_train, epochs=epoch, batch_size=32, verbose=2)\n",
        "    \n",
        "    if save==True:\n",
        "        model.save(f'{models_dir}/GRU/GRU_{event_name}_{time}')\n",
        "    return model\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY1lBjDjVWVs"
      },
      "source": [
        "def build_bi_LSTM(x_train, y_train,save,event_name,time,epoch=300):\n",
        "    seq = len(x_train)\n",
        "    units = int((seq +2) / 2)\n",
        "    look_back =2\n",
        "    \n",
        "    \n",
        "    model = keras.Sequential()\n",
        "    model.add(Bidirectional(LSTM(units),input_shape = (x_train.shape[1], look_back) ))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    model.compile( loss='mean_squared_error', optimizer='adam',metrics=[\"accuracy\"])\n",
        "    model.summary()\n",
        "\n",
        "    model.fit(x_train, y_train, epochs=epoch, batch_size=32, verbose=2)\n",
        "    \n",
        "    if save==True:\n",
        "        model.save(f'{models_dir}/BiLSTM/BiLSTM_{event_name}_{time}')\n",
        "    return model\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pV4bQluk7l8"
      },
      "source": [
        "def Build_Simple_Dense(x_train, y_train,save,event_name,time,epoch=300):\n",
        "    seq = len(x_train)\n",
        "    units = int((seq +2) / 2)\n",
        "    look_back =2\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(units,input_shape = (x_train.shape[1], look_back)))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    model.compile( loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
        "    model.summary()\n",
        "    model.fit(x_train, y_train, epochs=epoch, batch_size=32, verbose=2)\n",
        "    \n",
        "    if save==True:\n",
        "        model.save(f'{models_dir}/BiLSTM/BiLSTM_{event_name}_{time}')\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXAuA8owVYP9"
      },
      "source": [
        "def load_models(event,time):\n",
        "    # loading mdoel\n",
        "    models = []\n",
        "    models.append(keras.models.load_model(f'{models_dir}/LSTM/LSTM_{event_name}_{time}'))\n",
        "    models.append(keras.models.load_model(f'{models_dir}/SimpleRNN/SimpleRNN_{event_name}_{time}') )\n",
        "    models.append(keras.models.load_model(f'{models_dir}/GRU/GRU_{event_name}_{time}'))\n",
        "    models.append(keras.models.load_model(f'{models_dir}/BiLSTM/BiLSTM_{event_name}_{time}'))\n",
        "    models.append(keras.models.load_model(f'{models_dir}/TCNN/TCNN_{event_name}_{time}'))\n",
        "    return models\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei1tyyo0Va-N"
      },
      "source": [
        "def Ensembler_result(models,x_test):\n",
        "    array = None\n",
        "    for model in models:\n",
        "        if array is None:\n",
        "            array = model.predict(x_test)\n",
        "        else:\n",
        "            a = model.predict(x_test)\n",
        "            array = np.append(array,a, axis=1)\n",
        "    \n",
        "    result = []\n",
        "    for row in iter(array):\n",
        "        if (row >= 0.50).sum() >=3:\n",
        "            result.append(1)\n",
        "        else:\n",
        "            result.append(0)\n",
        "        \n",
        "    return np.array(result)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYNgQ8nVLKRO",
        "outputId": "cbe9f6d1-2f3c-4692-f52b-9b3bd14bebc4"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    # JUST CHANGE PARAMETERS HERE\n",
        "    # charliehebdo=0, ferguson=1, germanwings-crash=2, gurlitt=3, ottawashooting=4, putinmissing=5,sydneysiege=6\n",
        "\n",
        "    #=====================\n",
        "    EVENT = 0\n",
        "    # in seconds  120,300,600,1800,3600\n",
        "    TIME = 3600\n",
        "    t=[120,300,600,1800,3600]\n",
        "\n",
        "    RUN_FROM_SAVED_MODELS = False\n",
        "    \n",
        "    SAVE_MODEL_AFTER_TRAINING=True\n",
        "        #[\"charliehebdo\", \"ferguson\", \"germanwings-crash\", \"gurlitt\", \"ottawashooting\", \"putinmissing\",\"sydneysiege\"]\n",
        "    # time in seocnds\n",
        "    \n",
        "    data = load_data(event = EVENT, time=TIME)\n",
        "    \n",
        "    # splitted into 70 - 30\n",
        "    train, test = train_test_split(data, test_size=0.3)\n",
        "    \n",
        "    x_train = train.drop(columns=[\"status\"])\n",
        "    y_train = train[\"status\"] \n",
        "\n",
        "    scaler =  MinMaxScaler(feature_range=(0,1))\n",
        "    x_train = scaler.fit_transform(x_train)\n",
        "\n",
        "\n",
        "    x_test = test.drop(columns=[\"status\"])\n",
        "    y_test = test[\"status\"] \n",
        "\n",
        "    scaler =  MinMaxScaler(feature_range=(0,1))\n",
        "    x_test = scaler.fit_transform(x_test)\n",
        "\n",
        "    #pdb.set_trace()\n",
        "\n",
        "    # reshaping\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
        "    \n",
        "    # Running and Saving Models\n",
        "    model1 = build_LSTM(x_train,y_train,SAVE_MODEL_AFTER_TRAINING    ,EVENT,TIME,60 )\n",
        "    model2 = build_GRU(x_train,y_train,SAVE_MODEL_AFTER_TRAINING     ,EVENT,TIME  ,60)\n",
        "    model3 = build_bi_LSTM(x_train,y_train,SAVE_MODEL_AFTER_TRAINING ,EVENT,TIME  ,60)\n",
        "    model4 = build_RNN(x_train,y_train,SAVE_MODEL_AFTER_TRAINING     ,EVENT,TIME  ,60)    \n",
        "    #model5_A = build_tcnn(x_train,y_train,SAVE_MODEL_AFTER_TRAINING    ,EVENT,TIME  ,60)\n",
        "    #model5_B = Build_Simple_Dense(x_train,y_train,SAVE_MODEL_AFTER_TRAINING    ,EVENT,TIME  ,60)\n",
        "\n",
        "    \n",
        "    #if RUN_FROM_SAVED_MODELS == True:\n",
        "    #    models = load_models(EVENT,TIME)\n",
        "    #\n",
        "    #else: # use above build models \n",
        "    #    models = []\n",
        "    #    models.append(model1)\n",
        "    #    models.append(model2)\n",
        "    #    models.append(model3)\n",
        "    #    models.append(model4)\n",
        "    #    models.append(model5)\n",
        "    #result =  Ensembler_result(models,x_test)\n",
        "    #r = (result == y_test).sum()\n",
        "    #acc = r/len(y_test)\n",
        "    #\n",
        "    #TP,TN,FP,FN = build_confusion_matrix(y_test,result)\n",
        "    #\n",
        "    #accuracy = (TN+TP) /(TN+TP+FN+FP)\n",
        "    #precision = TP / (TP+FP)\n",
        "    #recall = TP /(TP+FN)\n",
        "    #f1_score = 2*((precision * recall)/(precision + recall))\n",
        "    #print('accuracy = ',accuracy)\n",
        "    #print('precision = ',precision)\n",
        "    #print('recall = ',recall)\n",
        "    #print('f1 score = ',f1_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      timeDiff  status  Freq\n",
            "0            0       0     0\n",
            "1            7       0     0\n",
            "2            9       0     0\n",
            "3           10       0     0\n",
            "4           11       0     4\n",
            "...        ...     ...   ...\n",
            "6801      3595       1     0\n",
            "6802      3596       1     1\n",
            "6803      3597       1     0\n",
            "6804      3598       1     0\n",
            "6805      3599       1     0\n",
            "\n",
            "[6806 rows x 3 columns]\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 2383)              22743352  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 2384      \n",
            "=================================================================\n",
            "Total params: 22,745,736\n",
            "Trainable params: 22,745,736\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "149/149 - 34s - loss: 0.6375 - accuracy: 0.6371\n",
            "Epoch 2/60\n",
            "149/149 - 29s - loss: 0.5223 - accuracy: 0.7540\n",
            "Epoch 3/60\n",
            "149/149 - 28s - loss: 0.5102 - accuracy: 0.7622\n",
            "Epoch 4/60\n",
            "149/149 - 29s - loss: 0.5085 - accuracy: 0.7630\n",
            "Epoch 5/60\n",
            "149/149 - 29s - loss: 0.5089 - accuracy: 0.7557\n",
            "Epoch 6/60\n",
            "149/149 - 29s - loss: 0.5003 - accuracy: 0.7657\n",
            "Epoch 7/60\n",
            "149/149 - 28s - loss: 0.4961 - accuracy: 0.7641\n",
            "Epoch 8/60\n",
            "149/149 - 29s - loss: 0.4892 - accuracy: 0.7704\n",
            "Epoch 9/60\n",
            "149/149 - 28s - loss: 0.4805 - accuracy: 0.7714\n",
            "Epoch 10/60\n",
            "149/149 - 38s - loss: 0.4734 - accuracy: 0.7754\n",
            "Epoch 11/60\n",
            "149/149 - 34s - loss: 0.4599 - accuracy: 0.7783\n",
            "Epoch 12/60\n",
            "149/149 - 28s - loss: 0.4500 - accuracy: 0.7821\n",
            "Epoch 13/60\n",
            "149/149 - 28s - loss: 0.4438 - accuracy: 0.7888\n",
            "Epoch 14/60\n",
            "149/149 - 29s - loss: 0.4409 - accuracy: 0.7838\n",
            "Epoch 15/60\n",
            "149/149 - 28s - loss: 0.4412 - accuracy: 0.7830\n",
            "Epoch 16/60\n",
            "149/149 - 28s - loss: 0.4383 - accuracy: 0.7825\n",
            "Epoch 17/60\n",
            "149/149 - 28s - loss: 0.4409 - accuracy: 0.7861\n",
            "Epoch 18/60\n",
            "149/149 - 28s - loss: 0.4400 - accuracy: 0.7838\n",
            "Epoch 19/60\n",
            "149/149 - 29s - loss: 0.4393 - accuracy: 0.7827\n",
            "Epoch 20/60\n",
            "149/149 - 37s - loss: 0.4369 - accuracy: 0.7844\n",
            "Epoch 21/60\n",
            "149/149 - 28s - loss: 0.4392 - accuracy: 0.7844\n",
            "Epoch 22/60\n",
            "149/149 - 27s - loss: 0.4378 - accuracy: 0.7857\n",
            "Epoch 23/60\n",
            "149/149 - 27s - loss: 0.4391 - accuracy: 0.7888\n",
            "Epoch 24/60\n",
            "149/149 - 28s - loss: 0.4366 - accuracy: 0.7859\n",
            "Epoch 25/60\n",
            "149/149 - 28s - loss: 0.4359 - accuracy: 0.7861\n",
            "Epoch 26/60\n",
            "149/149 - 28s - loss: 0.4356 - accuracy: 0.7859\n",
            "Epoch 27/60\n",
            "149/149 - 29s - loss: 0.4349 - accuracy: 0.7916\n",
            "Epoch 28/60\n",
            "149/149 - 29s - loss: 0.4405 - accuracy: 0.7926\n",
            "Epoch 29/60\n",
            "149/149 - 34s - loss: 0.4362 - accuracy: 0.7888\n",
            "Epoch 30/60\n",
            "149/149 - 28s - loss: 0.4353 - accuracy: 0.7911\n",
            "Epoch 31/60\n",
            "149/149 - 29s - loss: 0.4375 - accuracy: 0.7903\n",
            "Epoch 32/60\n",
            "149/149 - 28s - loss: 0.4376 - accuracy: 0.7853\n",
            "Epoch 33/60\n",
            "149/149 - 28s - loss: 0.4377 - accuracy: 0.7886\n",
            "Epoch 34/60\n",
            "149/149 - 28s - loss: 0.4369 - accuracy: 0.7890\n",
            "Epoch 35/60\n",
            "149/149 - 28s - loss: 0.4363 - accuracy: 0.7867\n",
            "Epoch 36/60\n",
            "149/149 - 30s - loss: 0.4361 - accuracy: 0.7897\n",
            "Epoch 37/60\n",
            "149/149 - 28s - loss: 0.4362 - accuracy: 0.7899\n",
            "Epoch 38/60\n",
            "149/149 - 27s - loss: 0.4359 - accuracy: 0.7842\n",
            "Epoch 39/60\n",
            "149/149 - 27s - loss: 0.4355 - accuracy: 0.7880\n",
            "Epoch 40/60\n",
            "149/149 - 27s - loss: 0.4356 - accuracy: 0.7832\n",
            "Epoch 41/60\n",
            "149/149 - 27s - loss: 0.4351 - accuracy: 0.7895\n",
            "Epoch 42/60\n",
            "149/149 - 27s - loss: 0.4363 - accuracy: 0.7861\n",
            "Epoch 43/60\n",
            "149/149 - 28s - loss: 0.4355 - accuracy: 0.7865\n",
            "Epoch 44/60\n",
            "149/149 - 27s - loss: 0.4350 - accuracy: 0.7890\n",
            "Epoch 45/60\n",
            "149/149 - 27s - loss: 0.4379 - accuracy: 0.7880\n",
            "Epoch 46/60\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}